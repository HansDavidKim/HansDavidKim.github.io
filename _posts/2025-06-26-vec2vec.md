---
layout: post
title: "논문 리뷰 : Harnessing the Universal Geometry of Embeddings"
categories: paper-review
tags: [paper-review]
math: true
---

## 1. Introduction
---
해당 논문은 Vec2Vec 알고리즘을 통하여 Platonic Representation Hypothesis 이 실증적으로 참임을 보여주며, 이를 통해 Vector DB 에서의 내용을 Semantic-level 에서 번역함으로서 보안에 문제가 될 수 있음을 제시한다.

#### Platonic Representation Hypothesis :
>Deep Learning 모델들이 다양한 데이터를 학습하며 이들이 학습한 표현은 서로 수렴하며, 이는 플라톤이 말하는 '이데아'와 같은 현실의 공통 구조로 향해 간다는 가설

기존의 Platonic Representation Hypothesis 는 vision model 에 국한된 내용이었으나, Cornell 대학교 연구팀은 위의 가설이 언어 모델에서도 성립함을 실험을 통해 실증적으로 보여주었다.

## 2. Problem Formulation : Unsupervised Embedding Translation
---
### Limitation of correspondence methods
기존의 다른 tokenizer 간의 임베딩을 대응시키는 방식은 서로 다른 임베딩 공간 정렬을 위해 입력 간에 강한 유사성을 전제로 하기에, 입력이나 tokenizer가 다를 경우 '의미' 정렬이 불가능하다는 근본적 한계 지점을 지닌다.

이를 해결하고자 논문에서는 <strong>Platonic Representation Hypothesis</strong>가 참이라 가정하여, 비지도 학습 방식으로 알려지지 않은 임베딩 공간의 벡터들을 알려진 임베딩 공간의 벡터들로 변환함으로서 의미적 정렬 및 번역을 수행한다.

<img src="https://miro.medium.com/v2/resize:fit:2000/1*EsmLEwXg0sp98F7PBKeOMw.png">

## 3. vec2vec
---
CV (Computer Vision) 분야에서, <strong>cycle consistency</strong>와 <strong>adversarial regularization</strong>을 통해 비지도 번역을 성공적으로 수행할 수 있다.

본 논문에서는 이 방식을 언어 모델로 확장하여 unsupervised embedding translation 태스크를 수행한다.
### 3.1 Architecture
1. <strong>입력 어댑터 (Input Adapter)</strong> :   각 어댑터는 각각의 임베딩 벡터를 universal latent representation의 차원의 벡터로 변환 시키는 역할을 수행한다.  
$A_1 : R^d \rightarrow R^z$   
$A_2 : R^d \rightarrow R^z$    

2. <strong>공유 백본 (Shared Backbone Network)</strong> : Adapted input에서 common latent embedding을 추출해낸다.  
$T : R^z\rightarrow R^z$

3. <strong>출력 어댑터 (Output Adapter)</strong> : common latent embedding을 다시 각 tokenizer에 맞는 embedding space 로 복원  
$B_1 : R^z \rightarrow R^d$  
$B_2 : R^z \rightarrow R^d$

위의 세 요소를 통해 Translation function $F_1,\,F_2$과 Reconstruction mapping $R_1,\,R_2$에 대해 다음과 같이 나타낼 수 있다.
> $F_1 = B_2 \circ T \circ A_1$  
$F_2 = B_1 \circ T \circ A_2$  
$R_1 = B_1 \circ T \circ A_1$  
$R_2 = B_2 \circ T \circ A_2$

이미지에서와는 달리, 임베딩은 spatial bias는 가지지 않는다. 그렇기에 기존의 방식인 CNN이 아닌 Residual Connection, MLP, layer normalization, SiLU 활성 함수를 통해 각 아키텍쳐를 구현한다.

Discriminator는 단순화를 위해 residual connection을 제거하고 위와 동일한 구조를 채택한다.

### 3.2 Optimization
---
앞으로 다룰 내용을 명료하게 이해하기 위해, GAN Loss에 대해 정의 및 기술하도록 하자.

GAN 기법은 기본적으로 generator model과 discriminator model 두 개를 활용하여 학습시키는 기법으로, generator는 discriminator를 더 "잘 속이도록", discriminator는 반대로 "더 잘 판별하도록" 경쟁적으로 학습하는 방식이다.

이를 반영한 Loss function은 아래와 같다.

#### GAN Loss / Minimax Loss
> $$\min_{G}\max_{D}V(D,G)=\mathbb{E}_{x\sim p_{data}}[\log D(x)]\,+\,\mathbb{E}_{z\sim p_z(z)}[1-D(G(z))]$$

각 항들을 해석해보면 실제 데이터 x를 참이라 판정할 확률에 대한 로그 값에 대한 기댓값과 생성된 데이터 z에 대해 거짓이라고 판정할 확률에 대한 로그 값에 대한 기댓값이다.

이를 최대화 하려는 Discriminator (판별자)와, 그걸 최소화 하고자 하는 Generator (생성자) 의 경쟁을 통해 GAN 방식은 생성자의 성능을 극대화 하고자 하는 프레임워크다.

다시 Vec2Vec으로 돌아와, 위의 GAN 방식을 적용해보자.  
각 architecture component의 parameters를 다음과 같이 표현하자.

$$\theta=\{A_1,A_2,T,B_1,B_2\}$$
<br>
vec2vec 최적화 문제를 다음과 같이 표현할 수 있다.

> $$\theta^*= \operatorname*{argmin}_{\theta}\max_{D_1,D_2, D_1^l,D_2^l}\mathcal{L}_{adv}(F_1,F_2,D_1,D_2,D_1^l,D_2^l)+\lambda_{gen}\mathcal{L}_{gen}(\theta)$$

지금 이 식만으로는 Loss function에 대해 바로 이해하기 어렵기에, 위의 loss를 앞서 다룬 GAN Loss를 활용해 분리하도록 하자.

#### 1. Adversarial Loss
> $$\mathcal{L}_{adv}(F_1,F_2,D_1,D_2,D_1^l,D_2^l)=\mathcal{L}_{GAN}(D_1,F_1)+\mathcal{L}_{GAN}(D_2,F_2)+\\\\ \mathcal{L}_{GAN}(D_1^l,T\circ A_1)+\mathcal{L}_{GAN}(D_2^l, T\circ A_2)$$ 

여기서 질문, $T\circ A_1$과 $T\circ A_2$ 둘 모두 common latent embedding에 해당 되기에 ground truth가 존재하지 않을 터인데 어떻게 학습이 가능한 것인가?

이는 다른 encoder가 생성한 common latent embedding 을 ground truth 라고 가정하여 학습하는 것으로, 두 common latent embedding 서로 간의 구분을 할 수 없는 방향으로 학습이 이루어지게 된다.

#### 2. Generator Loss
